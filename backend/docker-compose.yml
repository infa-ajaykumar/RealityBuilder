version: '3.8'

services:
  rabbitmq:
    image: rabbitmq:3-management-alpine
    container_name: rabbitmq_server
    ports:
      - "5672:5672"  # AMQP port for clients
      - "15672:15672" # Management UI
    environment:
      RABBITMQ_DEFAULT_USER: user
      RABBITMQ_DEFAULT_PASS: password
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
    networks:
      - backend_network

  craigslist_scraper:
    build:
      context: ./scraper_workers/craigslist_scraper
    container_name: craigslist_scraper_worker
    depends_on:
      - rabbitmq
    environment:
      RABBITMQ_HOST: rabbitmq_server # Matches the service name of RabbitMQ
      RABBITMQ_USER: user
      RABBITMQ_PASS: password
      RABBITMQ_QUEUE: property_listings_raw
    networks:
      - backend_network

  postgres_db:
    image: postgis/postgis:15-3.3
    container_name: postgres_db_container
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
      POSTGRES_DB: real_estate_db
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database_setup:/docker-entrypoint-initdb.d # Mount init scripts
    networks:
      - backend_network
    shm_size: '1g' # Recommended for PostGIS

  elasticsearch_db:
    image: elasticsearch:8.11.0
    container_name: elasticsearch_db_container
    ports:
      - "9200:9200"
      - "9300:9300"
    environment:
      discovery.type: single-node
      ES_JAVA_OPTS: "-Xms512m -Xmx512m"
      xpack.security.enabled: "false" # Ensure this is a string if YAML parses it as boolean
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    networks:
      - backend_network

  data_processing:
    build:
      context: ./data_processing
    container_name: data_processing_service
    depends_on:
      - rabbitmq
      - postgres_db
      - elasticsearch_db
    environment:
      RABBITMQ_URL: amqp://user:password@rabbitmq_server
      RABBITMQ_QUEUE: property_listings_raw
      POSTGRES_URL: postgresql://user:password@postgres_db:5432/real_estate_db
      ELASTICSEARCH_NODE: http://elasticsearch_db:9200
      ELASTICSEARCH_INDEX: properties
      NODE_ENV: development # Or production, depending on needs
    networks:
      - backend_network

  api_service:
    build:
      context: ./api_service
    container_name: api_service_node
    ports:
      - "3000:3000" # Expose API port to host
    environment:
      POSTGRES_URL: postgresql://user:password@postgres_db:5432/real_estate_db
      PORT: 3000
      ELASTICSEARCH_NODE: http://elasticsearch_db:9200
      ELASTICSEARCH_INDEX: properties
      REDIS_URL: redis://redis_cache_service:6379 # Added for Redis connection
      CACHE_TTL_PROPERTIES: "300" # 5 minutes
      CACHE_TTL_METADATA: "600"   # 10 minutes
      NODE_ENV: development # Or production
    depends_on:
      - postgres_db
      - elasticsearch_db
      - redis_cache_service # Added dependency for Redis
      # - data_processing # Optional: if API should wait for data processor
    networks:
      - backend_network

volumes:
  rabbitmq_data: # Defines the named volume for RabbitMQ
  postgres_data:   # Defines the named volume for PostgreSQL
  elasticsearch_data: # Defines the named volume for Elasticsearch

networks:
  backend_network:
    driver: bridge

  redis_cache:
    image: redis:7-alpine
    container_name: redis_cache_service
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - backend_network
    restart: always

  advanced_scraper_puppeteer:
    build:
      context: ./scraper_workers/advanced_scraper_puppeteer
    container_name: advanced_scraper_puppeteer_service
    restart: 'no' # Scrapers are often run on a schedule or manually
    depends_on:
      - rabbitmq # Ensure RabbitMQ is up before this service starts
    environment:
      RABBITMQ_URL: "amqp://user:password@rabbitmq_server"
      RABBITMQ_QUEUE: "property_listings_raw"
      TARGET_URL: "http://example-dynamic-site.com/listings" # Placeholder URL, replace with a real one for testing
      SOURCE_NAME: "DynamicSiteScraper"
      PUPPETEER_HEADLESS: "true" # Controls headless mode via environment
      NODE_ENV: "development" # Set to "production" for optimized builds if applicable
      # DEBUG: "puppeteer:*" # Uncomment for verbose Puppeteer logs
    networks:
      - backend_network
    # For some environments, if --no-sandbox and other args in puppeteer.launch are not enough,
    # you might need to add escalated privileges. This is generally discouraged if avoidable.
    # cap_add:
    #   - SYS_ADMIN
